name: ğŸš€ Auto Update arXiv Collection

# Quand exÃ©cuter:
# - Tous les jours Ã  2h du matin (UTC)
# - Manuellement depuis GitHub
# - Ã€ chaque push sur main (optionnel)
on:
  schedule:
    - cron: '0 2 * * *'  # Tous les jours Ã  2h UTC
  workflow_dispatch:  # Permet lancement manuel
  # push:
  #   branches: [ main ]  # DÃ©commente pour auto-update Ã  chaque push

jobs:
  update-collection:
    runs-on: ubuntu-latest
    
    steps:
    # 1. RÃ©cupÃ¨re le code du repo
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Garde tout l'historique
    
    # 2. Configure Python
    - name: ğŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    # 3. Installe les dÃ©pendances
    - name: ğŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests
    
    # 4. RÃ©cupÃ¨re la base de donnÃ©es existante (si elle existe)
    - name: ğŸ’¾ Download existing database
      continue-on-error: true
      run: |
        if [ -f "arxiv_full_collection.db" ]; then
          echo "âœ… Base de donnÃ©es existante trouvÃ©e"
        else
          echo "â„¹ï¸  Pas de base existante, on va en crÃ©er une nouvelle"
        fi
    
    # 5. Collecte les nouveaux articles (annÃ©e en cours seulement)
    - name: ğŸ“š Collect new articles
      run: |
        echo "ğŸš€ Collection des articles de $(date +%Y)..."
        python3 arxiv_full_collector.py collect $(date +%Y) $(date +%Y)
      timeout-minutes: 120  # Max 2 heures
    
    # 6. Export vers JSON
    - name: ğŸ“¤ Export to JSON
      run: |
        echo "ğŸ“¤ Export vers articles.json..."
        python3 arxiv_full_collector.py export articles.json
    
    # 7. VÃ©rifie la taille du JSON
    - name: ğŸ“Š Check JSON size
      run: |
        size=$(du -h articles.json | cut -f1)
        echo "ğŸ“¦ Taille du JSON: $size"
        
        # Alerte si > 100MB
        size_bytes=$(stat -c%s articles.json)
        if [ $size_bytes -gt 104857600 ]; then
          echo "âš ï¸  WARNING: JSON > 100MB ($size)"
          echo "Consider using Git LFS or filtering data"
        fi
    
    # 8. Affiche les stats
    - name: ğŸ“Š Show statistics
      run: |
        python3 arxiv_full_collector.py stats
    
    # 9. Commit et push les changements
    - name: ğŸ’¾ Commit and push changes
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        
        # Ajoute les fichiers modifiÃ©s
        git add articles.json
        git add arxiv_full_collection.db
        
        # VÃ©rifie s'il y a des changements
        if git diff --staged --quiet; then
          echo "â„¹ï¸  Pas de nouveaux articles"
        else
          # Commit
          git commit -m "ğŸ”„ Auto-update: $(date '+%Y-%m-%d %H:%M UTC') [skip ci]"
          
          # Push
          git push
          
          echo "âœ… Changements poussÃ©s vers GitHub"
        fi
    
    # 10. CrÃ©e un artifact (backup)
    - name: ğŸ“¦ Upload artifacts
      uses: actions/upload-artifact@v3
      with:
        name: arxiv-collection-${{ github.run_number }}
        path: |
          articles.json
          arxiv_full_collection.db
        retention-days: 30  # Garde 30 jours

  # Job sÃ©parÃ© pour dÃ©ployer sur GitHub Pages
  deploy:
    needs: update-collection
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout
      uses: actions/checkout@v4
      with:
        ref: main
    
    - name: ğŸš€ Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./
        publish_branch: gh-pages
        exclude_assets: '.github,*.py,*.sh,*.db'
